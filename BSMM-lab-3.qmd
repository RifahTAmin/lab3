---
title: "BSMM-lab-3"
subtitle: "BSMM 8740 Fall 2023"
author: "Rifah Tasfia Amin"
date: "13/10/2023"
format: html
editor: visual
self-contained: true
---

## Setup

Load packages and data:

```{r load-pkg-data}
#| message: false
# install.packages("skimr") #
# install.packages("janitor") #
# install.packages("tidymodels") #

boston_cocktails <- readr::read_csv('data/boston_cocktails.csv')
```

## Exercises

### Exercise 1

The median measure amount across all cocktails is \_\_\_.

```{r}
# Load the required libraries #
library(magrittr)   # the pipe
library(tidyverse)  # for data wrangling + visualization
library(tidymodels) # for modeling
library(gt) # for pretty tables


boston_cocktails <- readr::read_csv('data/boston_cocktails.csv') # Load the Boston Cocktail Recipes data set #

# Use skim to assess dataset quality
skimr::skim(boston_cocktails)

# Use introduce to explore variables in the dataset 
DataExplorer::introduce(boston_cocktails)

# Calculate the median measure number
median_measure_number <- median(boston_cocktails$measure_number)
print(median_measure_number)
```

The median measure amount across across all cocktails is 1.

### Exercise 2

The **Leap Frog Highball** contains \_\_\_ of gin

```{r}

#load the libraries #

library(tidyverse)
library(janitor)

#Select the columns mentioned #
select_columns <- boston_cocktails |>
  select(name, category, ingredient, measure_number)

# Pivot the table to create columns for each ingredient and fill missing values with zero #
pivoted_table <- select_columns |>
  pivot_wider(names_from = ingredient, values_from = measure_number, values_fill = 0)

# Clean column names #
cleaned_table <- pivoted_table |>
  janitor::clean_names()


# Evaludate how much gin is in the cocktail called Leap Frog Highball
gin_in_leap_frog_highball <- cleaned_table |>
  filter(name == "Leap Frog Highball") |>
  select(gin)

print(gin_in_leap_frog_highball)
```

The **Leap Frog Highball** contains 2 of gin

### Exercise 3

\_\_\_ predictor variables are prepped by the recipe.

```{r}

library(recipes)


boston_cocktails <- read.csv("data/boston_cocktails.csv", header = TRUE)
View(boston_cocktails)

# Create a recipe object using the loaded dataset
recipe_obj <- recipe(~ ., data = boston_cocktails) |>
  update_role(name, category, new_role = "id") |>
  step_dummy(all_nominal()) |>
  step_normalize(all_numeric()) |>
  step_pca(all_numeric(), num_comp = 3)

# Prepare the data
prepped_data <- prep(recipe_obj)

# Count the number of predictor variables prepped by the recipe
num_predictor_vars <- length(prepped_data$predictors)
print(num_predictor_vars)

```

0 predictor variables are prepped by the recipe.

### Exercise 4

On average the most used ingredient in the Boston Cocktails dataset is \_\_\_\_.

```{r}

# Summarize the data to find the most used ingredient on average
ingredient_summary <- boston_cocktails |>
  group_by(ingredient) |>
  summarize(avg_measure_number = mean(measure_number, na.rm = TRUE)) |>
  arrange(desc(avg_measure_number))

most_used_ingredient <- ingredient_summary$ingredient[1]

print(most_used_ingredient ) # display the most used ingredient on an average #
```

On average the most used ingredient in the Boston Cocktails dataset is cranberry juice.

### Exercise 5

Describe the drinks represented by PC1?

1.  If a data point falls within the range of 0 to 0.25 and positively influences PC1, it means that when data points are in this range, they tend to increase the value of PC1.

2.  When the measure number is between 0 and -0.7 and it has a negative effect on PC1, it suggests that data points in this range tend to decrease the value of PC1.

3.  If the ingredient number falls within the range of 0 to 0.7 and has a positive impact on PC1, it implies that data points in this range tend to boost the value of PC1.

```{r}
library(recipes)
library(dplyr)
library(forcats)
library(ggplot2)

# Assuming 'boston_cocktails' is your dataset
numeric_columns <- select_if(boston_cocktails, is.numeric)

boston_cocktails_recipe <-
  recipe(~., data = numeric_columns) %>% 
  update_role(., row_id, ingredient_number, measure_number) %>% 
  step_naomit(all_predictors()) %>% 
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), id = "pca") %>% 
  prep()

boston_cocktails_pca <- 
  boston_cocktails_recipe %>% 
  tidy(id = "pca", matrix = "X") # Use matrix = "X" to keep the original data matrix

# Filter for components PC1 to PC5 and mutate them as factors
boston_cocktails_pca_filtered <- boston_cocktails_pca %>%
  filter(component %in% c("PC1", "PC2", "PC3", "PC4", "PC5")) %>%
  mutate(component = fct_inorder(component))

# Create the PCA plot
ggplot(boston_cocktails_pca_filtered, aes(x = value, y = terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL) +
  theme(axis.text = element_text(size = 7),
        axis.title = element_text(size = 14, face = "bold"))

```

### Exercise 6

The characteristic alcoholic beverage of each of the first 4 principle components is \_\_\_.

```{r}
# Load required libraries
library(dplyr)
library(gt)

# Assuming 'boston_cocktails_pca_filtered' contains your PCA data
# Replace it with your actual data if necessary

# Create a function to color cells based on value
color_cells <- function(x) {
  ifelse(x < 0, "red", "green")
}

# Slice the top 8 ingredients by component based on absolute value
top_ingredients_table <- boston_cocktails_pca_filtered %>%
  filter(component %in% c("PC1", "PC2", "PC3", "PC4")) %>%
  group_by(component) %>%
  slice_max(order_by = abs(value), n = 8) %>%
  ungroup() %>%
  pivot_wider(names_from = component, values_from = terms)

# Modify the table to add cell background colors using gt
for (col in names(top_ingredients_table)[-1]) {
  top_ingredients_table[[col]] <- sapply(top_ingredients_table[[col]], function(x) {
    cell_style <- color_cells(x)
    sprintf('<span style="background-color: %s">%s</span>', cell_style, x)
  })
}

# Create the gt table
table_pca_ingredients <- top_ingredients_table %>%
  gt() %>%
  tab_style(
    style = cell_fill(
      color = color_cells(0)
    ),
    locations = cells_body()
  )

# Print the table
table_pca_ingredients
```

### Exercise 7

```{r}

# Load required libraries
library(dplyr)
library(recipes)
library(ggplot2)


# Assuming 'boston_cocktails' is your data frame

# Create the PCA recipe
rec <- recipe(~., data = boston_cocktails)
pca_trans <- rec %>%
  step_normalize(all_numeric()) %>%
  step_pca(all_numeric(), num_comp = 3)
pca_estimates <- prep(pca_trans, training = boston_cocktails)
pca_data <- bake(pca_estimates, boston_cocktails)

# Extend the range for the plot
rng <- extendrange(c(pca_data$PC1, pca_data$PC2))


# Create PCA with threshold
with_thresh <- rec %>%
  step_normalize(all_numeric()) %>%
  step_pca(all_numeric(), threshold = 0.99)
with_thresh <- prep(with_thresh, training = boston_cocktails)
baked_with_thresh <- bake(with_thresh, boston_cocktails)

# Print tidy PCA results
tidy(pca_trans, number = 2)
tidy(pca_estimates, number = 2)

# Create the scatter plot of PC1 and PC2 with labels
ggplot(pca_data, aes(PC1, PC2, label = name)) +
  geom_point(aes(color = category), alpha = 0.7, size = 2) +
  geom_text(check_overlap = TRUE, hjust = "inward") + 
  labs(color = NULL)
```

How would you interpret the results of a PCA analysis for a client?

In this PCA analysis, when we look at the first two principal components (PC1 and PC2), they don't really show a clear separation between the data points. This implies that the dataset doesn't have strong patterns or differences easily seen in these two dimensions. To discover any underlying, hidden patterns, we may need to dig deeper and examine higher-dimensional components beyond PC1 and PC2.
